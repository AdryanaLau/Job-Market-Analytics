**Imports**:
   ```python
   import urllib.parse
   import requests
   from bs4 import BeautifulSoup
   import json
   ```
   - The script starts by importing necessary modules: `urllib.parse` for constructing URLs, `requests` for making HTTP requests, `BeautifulSoup` for web scraping, and `json` for handling JSON data.
**URL Construction Function**:
   ```python
   def construct_url(job_title, location):
       base_url = 'https://www.seek.com.au/'
       encoded_job_title = urllib.parse.quote(job_title)
       encoded_location = urllib.parse.quote(location)
       url = f'{base_url}{encoded_job_title}-jobs/in-All-{encoded_location}'
       return url
   ```
   - The `construct_url` function takes `job_title` and `location` as parameters, URL-encodes them, and constructs a Seek job search URL.
**Load Jobs Function**:
   ```python
   def load_jobs(url):
       try:
           page = requests.get(url)
           page.raise_for_status()  # Raise an HTTPError for bad responses
           soup = BeautifulSoup(page.content, "html.parser")
           job_soup = soup.find_all("div", class_='_1wkzzau0 a1msqi6m')
           return job_soup
       except requests.RequestException as e:
           print(f"Error loading page: {e}")
           return []
   ```
   - The `load_jobs` function takes a URL, makes a request to the website, checks for errors, and returns a list of job elements found on the page.
**Extract Job Information Function**:
   ```python
   def extract_job_info(job_elem):
       title_elem = job_elem.find('h3', class_='your-title-class')  # Replace with the correct class
       company_elem = job_elem.find('span', class_='your-company-class')  # Replace with the correct class
       title = title_elem.text.strip() if title_elem else "No Title"
       company = company_elem.text.strip() if company_elem else "No Company"
       return {'title': title, 'company': company}
   ```
   - The `extract_job_info` function takes a job element, extracts the title and company information, and returns a dictionary.
**Main Function**:
   ```python
   def main():
       job_title = 'data-analyst'
       location = 'Perth-WA'
       url = construct_url(job_title, location)
       jobs = load_jobs(url)
       job_info_list = [extract_job_info(job) for job in jobs]
       titles = [job['title'] for job in job_info_list]
       companies = [job['company'] for job in job_info_list]
       result_dict = {'titles': titles, 'companies': companies}
       with open('job_info.json', 'w') as json_file:
           json.dump(result_dict, json_file)
       print("Titles and companies extracted and saved to 'job_info.json'")
   ```
   - The `main` function sets the job title and location, constructs the URL, loads job elements, extracts job information, creates lists of titles and companies, creates a dictionary, and saves the data to a JSON file.
**Main Function Execution**:
   ```python
   if __name__ == "__main__":
       main()
   ```
