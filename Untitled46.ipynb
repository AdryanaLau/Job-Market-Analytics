{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdryanaLau/Job-Market-Analytics/blob/main/Untitled46.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6T-cR1MigBLJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54e1e561-ca71-4e7c-fe3f-d0cb90a0a8f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     title company link posting_date\n",
            "0                                   \n",
            "1                                   \n",
            "2                                   \n",
            "3                                   \n",
            "4                                   \n",
            "...    ...     ...  ...          ...\n",
            "1225                                \n",
            "1226                                \n",
            "1227                                \n",
            "1228                                \n",
            "1229                                \n",
            "\n",
            "[1230 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the CSV file\n",
        "df = pd.read_csv('combined_job_info (1).csv')\n",
        "\n",
        "# Replace blank values with \"Na\"\n",
        "df.replace({np.nan: 'Na'}, inplace=True)\n",
        "\n",
        "# Remove \"at\" from the beginning of the 'company' column\n",
        "df['company'] = df['company'].str.replace('^at ', '', regex=True)\n",
        "\n",
        "# Remove \"Where\", \"What\", \"No Company\" from the 'company' column\n",
        "df['company'] = df['company'].replace(['Where', 'What', 'No Company'], '', regex=True)\n",
        "\n",
        "# Remove \"No Title\" from the 'title' column\n",
        "df['title'] = df['title'].replace('No Title', '', regex=True)\n",
        "\n",
        "# Remove \"No Link\" from the 'link' column\n",
        "df['link'] = df['link'].replace('No Link', '', regex=True)\n",
        "\n",
        "# Remove \"No Date\" from the 'posting_date' column\n",
        "df['posting_date'] = df['posting_date'].replace('No Date', '', regex=True)\n",
        "\n",
        "# Replace values in 'posting_date' with '0d ago' if more than 15 characters\n",
        "df['posting_date'] = np.where(df['posting_date'].str.len() > 15, '0d ago', df['posting_date'])\n",
        "\n",
        "# Remove rows with blank values\n",
        "df = df.dropna()\n",
        "\n",
        "# Save the cleaned DataFrame to a new CSV file\n",
        "df.to_csv('cleaned_job_info.csv', index=False)\n",
        "\n",
        "# Display the cleaned DataFrame\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ljo-YM5ogBxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the CSV file\n",
        "df = pd.read_csv('combined_job_info (1).csv')\n",
        "\n",
        "# Replace blank values with \"Na\"\n",
        "df.replace({np.nan: 'Na'}, inplace=True)\n",
        "\n",
        "# Remove \"at\" from the beginning of the 'company' column\n",
        "df['company'] = df['company'].str.replace('^at ', '', regex=True)\n",
        "\n",
        "# Remove \"Where\", \"What\", \"No Company\" from the 'company' column\n",
        "df['company'] = df['company'].replace(['Where', 'What', 'No Company'], '', regex=True)\n",
        "\n",
        "# Remove \"No Title\" from the 'title' column\n",
        "df['title'] = df['title'].replace('No Title', '', regex=True)\n",
        "\n",
        "# Remove \"No Link\" from the 'link' column\n",
        "df['link'] = df['link'].replace('No Link', '', regex=True)\n",
        "\n",
        "# Remove \"No Date\" from the 'posting_date' column\n",
        "df['posting_date'] = df['posting_date'].replace('No Date', '', regex=True)\n",
        "\n",
        "# Replace values in 'posting_date' with '0d ago' if more than 15 characters\n",
        "df['posting_date'] = np.where(df['posting_date'].str.len() > 15, '0d ago', df['posting_date'])\n",
        "\n",
        "# Remove rows with blank values\n",
        "df = df.dropna()\n",
        "\n",
        "# Create a new column 'date_posting_clean'\n",
        "df['date_posting_clean'] = df['posting_date'].str.replace('[dh ago]+', '', regex=True)\n",
        "\n",
        "# Convert the new column to numeric\n",
        "df['date_posting_clean'] = pd.to_numeric(df['date_posting_clean'], errors='coerce')\n",
        "\n",
        "# Convert hours ('h' values) to equivalent days\n",
        "df.loc[df['posting_date'].str.contains('h'), 'date_posting_clean'] /= 24\n",
        "\n",
        "# Save the cleaned DataFrame to a new CSV file\n",
        "df.to_csv('cleaned_job_info_with_days.csv', index=False)\n",
        "\n",
        "# Display the cleaned DataFrame\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "Voq_Px3Nh5o-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61c6db23-ae5b-4a7d-d670-b77ada0f813c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     title company link posting_date  date_posting_clean\n",
            "0                                                    NaN\n",
            "1                                                    NaN\n",
            "2                                                    NaN\n",
            "3                                                    NaN\n",
            "4                                                    NaN\n",
            "...    ...     ...  ...          ...                 ...\n",
            "1225                                                 NaN\n",
            "1226                                                 NaN\n",
            "1227                                                 NaN\n",
            "1228                                                 NaN\n",
            "1229                                                 NaN\n",
            "\n",
            "[1230 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the CSV file\n",
        "df = pd.read_csv('cleaned_job_info_with_days.csv')\n",
        "\n",
        "# Drop rows with any blank values\n",
        "df = df.dropna()\n",
        "\n",
        "# Save the DataFrame without blank rows to a new CSV file\n",
        "df.to_csv('cleaned_job_info_without_blank_rows.csv', index=False)\n",
        "\n",
        "# Display the cleaned DataFrame\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "Yqdj-cEm0D-2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f729d72-e6e3-4cd1-89d1-de6f787cd945"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          title  \\\n",
            "10                    Senior/Principal Botanist   \n",
            "12                    Data Analyst Project Lead   \n",
            "15                                 Data Analyst   \n",
            "17                Workplace Health Data Analyst   \n",
            "21                               Data Scientist   \n",
            "...                                         ...   \n",
            "1197  Project Development Engineer - Signalling   \n",
            "1199                       Senior Data Engineer   \n",
            "1201                              Administrator   \n",
            "1203                 Project Automation Support   \n",
            "1218           Sr Project Automation Specialist   \n",
            "\n",
            "                                         company  \\\n",
            "10                 Biologic Environmental Survey   \n",
            "12    Department of Planning, Lands and Heritage   \n",
            "15                                 Alinta Energy   \n",
            "17                                RED OHMS Group   \n",
            "21                                   PERSOLKELLY   \n",
            "...                                          ...   \n",
            "1197                  Arc Infrastructure Pty Ltd   \n",
            "1199                 Telstra Corporation Limited   \n",
            "1201                                       Orica   \n",
            "1203                                     Bechtel   \n",
            "1218                     Fluor Australia Pty Ltd   \n",
            "\n",
            "                                                   link posting_date  \\\n",
            "10    https://www.seek.com.au//job/72034822?type=pro...       0d ago   \n",
            "12    https://www.seek.com.au//job/72225999?type=pro...       0d ago   \n",
            "15    https://www.seek.com.au//job/72205049?type=sta...       4d ago   \n",
            "17    https://www.seek.com.au//job/72104312?type=sta...       8d ago   \n",
            "21    https://www.seek.com.au//job/72180513?type=sta...       4d ago   \n",
            "...                                                 ...          ...   \n",
            "1197  https://www.seek.com.au//job/72217716?type=sta...       3d ago   \n",
            "1199  https://www.seek.com.au//job/72251002?type=sta...       1d ago   \n",
            "1201  https://www.seek.com.au//job/71894229?type=sta...      17d ago   \n",
            "1203  https://www.seek.com.au//job/71841611?type=sta...      19d ago   \n",
            "1218  https://www.seek.com.au//job/71687226?type=sta...      26d ago   \n",
            "\n",
            "      date_posting_clean  \n",
            "10                   0.0  \n",
            "12                   0.0  \n",
            "15                   4.0  \n",
            "17                   8.0  \n",
            "21                   4.0  \n",
            "...                  ...  \n",
            "1197                 3.0  \n",
            "1199                 1.0  \n",
            "1201                17.0  \n",
            "1203                19.0  \n",
            "1218                26.0  \n",
            "\n",
            "[385 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XmfoBOGAiZQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mode and its frequency of 'job_title'\n",
        "title_counts = df['title'].value_counts()\n",
        "mode_result = title_counts[title_counts == title_counts.max()]\n",
        "\n",
        "if not mode_result.empty:\n",
        "    mode_job_title = mode_result.index[0]  # The mode(s) can be multiple, so we take the first one\n",
        "    mode_frequency = mode_result.iloc[0]\n",
        "    print(f\"Mode of job_title: {mode_job_title}, Frequency: {mode_frequency}\")\n",
        "\n",
        "    # Create a DataFrame with job titles and their frequencies\n",
        "    title_frequency_df = pd.DataFrame({'Title': title_counts.index, 'Frequency': title_counts.values})\n",
        "\n",
        "    # Save the DataFrame to a new CSV file\n",
        "    title_frequency_df.to_csv('job_title_frequencies.csv', index=False)\n",
        "    print(\"Job title frequencies saved to 'job_title_frequencies.csv'\")\n",
        "else:\n",
        "    print(\"No mode found for job_title.\")\n"
      ],
      "metadata": {
        "id": "C2fPBlEN1Bc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4375884b-e41a-4c3f-b3fb-9333fcefe545"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mode of job_title: Data Scientist, Frequency: 12\n",
            "Job title frequencies saved to 'job_title_frequencies.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FZaOeFTt1g06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2A4WsCD2xkjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ola3OXrMglqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ale8Iq6lxGIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nssb2ZO_gt64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cGN9LK53q0DX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8VkAJKixrfmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EpexlX9RsmEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gDxAjFo1s2D9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}